<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>Content Page</title>
    <style>
      /* Glassmorphism styles */
      body {
        /*background: linear-gradient(to bottom, rgba(255, 255, 255, 0.9) 0%, rgba(255, 255, 255, 0.9) 100%);*/
        background-color: #fff;
        background-size: cover;
        font-family: "Helvetica Neue", sans-serif;
        color: #333;
      }
      
      /* Theme switcher styles */
      #toggle-theme-button {
        background-color: transparent;
        border: none;
        outline: none;
        position: absolute;
        top: 20px;
        right: 20px;
        height: 80px;
        width: 80px;
        padding: 10px;
        font-size: 0px;
      }
      .toggle-theme-button i {
    font-size: 104px;
}

.icon {
  height: 24px;
  width: 24px;
  font-size: 100px;
  display: none;
}

#home {
  display: block;
  fill: #fff
}
      #home:hover {
        fill: #000;
      }

#light-icon {
  display: block;
}

.dark-theme #light-icon {
  display: none;
}

.dark-theme #dark-icon {
  display: block;
}
      .dark-theme {
        background-color: #121212;
      }
      
      /* Content styles */
      .content {
        
        max-width: 800px;
        margin: 100px auto;
        text-align: center;
      }
      .dark-theme .content{
        color:rgb(214, 214, 214)
      }
      h1 {
        font-size: 42px;
        margin-bottom: 40px;
      }
      h2 {
        font-size: 24px;
        margin-bottom: 10px;
      }
      p {
        font-size: 18px;
        line-height: 1.5;
        margin-bottom: 25px;
      }
      a {
        display: inline-block;
        padding: 10px 20px;
        background-color: #333;
        color: #fff;
        border-radius: 20px;
        text-decoration: none;
        transition: all 0.3s;
      }
      a:hover {
        background-color: #fff;
        color: #333;
      }
      li {
        font-size: 18px;
        line-height: 1;
        margin-bottom: 15px;
      }
    </style>
  </head>
  <body class="light-theme">
    <!-- Theme switcher button -->
    
    
    <!-- Content -->
    <div class="content">
        
        
            <h1>Алгоритм K-ближайших соседей (KNN)</h1>
            <p>K-Ближайшие соседи (KNN) - популярный алгоритм машинного обучения, используемый для задач классификации и регрессии. Это непараметрический и ленивый алгоритм обучения, который предполагает, что похожие экземпляры, как правило, находятся рядом друг с другом в пространстве объектов. Алгоритм определяет класс или значение нового экземпляра, учитывая класс большинства или среднее значение его ближайших соседей в обучающих данных.</p>
            <h2>Как работает KNN</h2>
            <p>Алгоритм KNN основан на концепции сходства между экземплярами. Чтобы определить класс или значение нового экземпляра, алгоритм сначала находит K ближайших соседей экземпляра в обучающих данных. Затем он определяет класс или значение нового экземпляра на основе класса большинства или среднего значения его ближайших соседей. Значение K - это гиперпараметр, который определяет количество ближайших соседей для рассмотрения, и обычно оно устанавливается путем перекрестной проверки или методом проб и ошибок.</p>
            <h2>Применение KNN</h2>
            <p>KNN имеет несколько реальных приложений, в том числе:</p>
            <ul>
             <li>Классификация: KNN может использоваться для классификации объектов по различным категориям на основе их характеристик. Например, KNN можно использовать для классификации изображений по различным категориям объектов на основе их значений в пикселях.</li>
             <li>Регрессия: KNN также может использоваться для прогнозирования непрерывных значений, таких как цена дома или стоимость акций. В этом случае KNN вычисляет среднее значение своих ближайших соседей и использует его в качестве прогноза для нового экземпляра.</li>
             <li>Обнаружение аномалий: KNN также можно использовать для обнаружения аномалий или выбросов в данных, рассматривая экземпляры, которые находятся далеко от его ближайших соседей, как аномалии.</li>
             <li> Рекомендательные системы: KNN также можно использовать в рекомендательных системах, находя ближайших соседей пользователя или элемента и рекомендуя элементы или пользователей, которые наиболее похожи на цель.</li>
            </ul>
            <h2>Преимущества KNN</h2>
            <ul>
             <li> Простой и понятный: KNN - это простой и понятный алгоритм, который может быть легко понят даже неспециалистами в области машинного обучения.</li>
             <li> Без фазы обучения: В отличие от других алгоритмов машинного обучения, у которых есть фаза обучения, KNN - это алгоритм ленивого обучения, который не требует никакого обучения. Он просто использует экземпляры в обучающих данных для составления прогнозов.</li>
             <li> Возможность адаптации: KNN - это универсальный алгоритм, который может использоваться для различных типов задач, включая классификацию, регрессию и обнаружение аномалий.</li>
             <li>Непараметрический: KNN - это непараметрический алгоритм, который не делает никаких предположений о лежащем в основе распределении данных, что делает его подходящим для работы со сложными и нелинейными данными.</li>
            </ul>
            <h2>Недостатки KNN</h2>
            <ul>
             <li> Вычислительные затраты: KNN может быть дорогостоящим с точки зрения вычислений, особенно когда размер обучающих данных велик. Это связано с тем, что алгоритму необходимо вычислить расстояние между новым экземпляром и всеми экземплярами в обучающих данных, чтобы найти ближайших соседей.</li>
             <li>Чувствительность к нерелевантным функциям: на KNN могут влиять нерелевантные или зашумленные функции в данных, поскольку они могут увеличить расстояние между экземплярами и привести к неправильным прогнозам. Чтобы смягчить это, важно тщательно обработать данные и выбрать соответствующие функции перед использованием KNN.</li>
            <li>Переменное качество результатов: Качество результатов, получаемых KNN, может сильно варьироваться в зависимости от значения K и распределения данных. Это означает, что найти оптимальное значение K и оценить производительность KNN на основе данных может быть непросто.</li> <li> Интенсивное использование памяти: KNN хранит все экземпляры обучающих данных в памяти, что может быть проблематичным для больших наборов данных и ограничивать масштабируемость алгоритма.</li> </ul>
            <h2>Заключение</h2> <p>В заключение, K-Nearest Neighbors (KNN) - это простой и универсальный алгоритм машинного обучения, который может быть использован для различных задач, включая классификацию, регрессию и обнаружение аномалий. Несмотря на свою простоту, KNN имеет ряд недостатков, включая вычислительную стоимость, чувствительность к нерелевантным функциям и переменное качество результатов. Тем не менее, KNN остается полезным инструментом в наборе инструментов машинного обучения и может обеспечить хорошие результаты при правильном использовании.</p>
            <a href="linear-regression.html">Previous Page</a>
            <a href="index.html"><svg id="home" class="icon" width="100" height="100">
                <path d="M3.95709826,8.41510662 L11.47855,3.81866389 C11.7986624,3.62303967 12.2013376,3.62303967 12.52145,3.81866389 L20.0429,8.41510557 C20.6374094,8.77841684 21,9.42493654 21,10.1216692 L21,19.0000642 C21,20.1046337 20.1045695,21.0000642 19,21.0000642 L4.99998155,21.0000673 C3.89541205,21.0000673 2.99998155,20.1046368 2.99998155,19.0000673 L2.99999828,10.1216672 C2.99999935,9.42493561 3.36258984,8.77841732 3.95709826,8.41510662 Z M10,13 C9.44771525,13 9,13.4477153 9,14 L9,17 C9,17.5522847 9.44771525,18 10,18 L14,18 C14.5522847,18 15,17.5522847 15,17 L15,14 C15,13.4477153 14.5522847,13 14,13 L10,13 Z"/>
        
              </svg>
              
            </a>
      <a href="neural-networks.html">Next Page</a>
    </div>
    
    <button id="toggle-theme-button" onclick="toggleTheme()">
        
        <svg id="light-icon" class="icon" width="100" height="100">
          <path d="M12.0700837,4.0003006 C11.3895108,5.17692613 11,6.54297551 11,8 C11,12.3948932 14.5439081,15.9620623 18.9299163,15.9996994 C17.5467214,18.3910707 14.9612535,20 12,20 C7.581722,20 4,16.418278 4,12 C4,7.581722 7.581722,4 12,4 C12.0233848,4 12.0467462,4.00010034 12.0700837,4.0003006 Z" fill="#000"/>
        </svg>

        <svg id="dark-icon" class="icon">
            <rect x="0" y="0" width="1000" height="1000"/>
            <path d="M12,15 C10.3431458,15 9,13.6568542 9,12 C9,10.3431458 10.3431458,9 12,9 C13.6568542,9 15,10.3431458 15,12 C15,13.6568542 13.6568542,15 12,15 Z" fill="#fff" fill-rule="nonzero"/>
            <path d="M19.5,10.5 L21,10.5 C21.8284271,10.5 22.5,11.1715729 22.5,12 C22.5,12.8284271 21.8284271,13.5 21,13.5 L19.5,13.5 C18.6715729,13.5 18,12.8284271 18,12 C18,11.1715729 18.6715729,10.5 19.5,10.5 Z M16.0606602,5.87132034 L17.1213203,4.81066017 C17.7071068,4.22487373 18.6568542,4.22487373 19.2426407,4.81066017 C19.8284271,5.39644661 19.8284271,6.34619408 19.2426407,6.93198052 L18.1819805,7.99264069 C17.5961941,8.57842712 16.6464466,8.57842712 16.0606602,7.99264069 C15.4748737,7.40685425 15.4748737,6.45710678 16.0606602,5.87132034 Z M16.0606602,18.1819805 C15.4748737,17.5961941 15.4748737,16.6464466 16.0606602,16.0606602 C16.6464466,15.4748737 17.5961941,15.4748737 18.1819805,16.0606602 L19.2426407,17.1213203 C19.8284271,17.7071068 19.8284271,18.6568542 19.2426407,19.2426407 C18.6568542,19.8284271 17.7071068,19.8284271 17.1213203,19.2426407 L16.0606602,18.1819805 Z M3,10.5 L4.5,10.5 C5.32842712,10.5 6,11.1715729 6,12 C6,12.8284271 5.32842712,13.5 4.5,13.5 L3,13.5 C2.17157288,13.5 1.5,12.8284271 1.5,12 C1.5,11.1715729 2.17157288,10.5 3,10.5 Z M12,1.5 C12.8284271,1.5 13.5,2.17157288 13.5,3 L13.5,4.5 C13.5,5.32842712 12.8284271,6 12,6 C11.1715729,6 10.5,5.32842712 10.5,4.5 L10.5,3 C10.5,2.17157288 11.1715729,1.5 12,1.5 Z M12,18 C12.8284271,18 13.5,18.6715729 13.5,19.5 L13.5,21 C13.5,21.8284271 12.8284271,22.5 12,22.5 C11.1715729,22.5 10.5,21.8284271 10.5,21 L10.5,19.5 C10.5,18.6715729 11.1715729,18 12,18 Z M4.81066017,4.81066017 C5.39644661,4.22487373 6.34619408,4.22487373 6.93198052,4.81066017 L7.99264069,5.87132034 C8.57842712,6.45710678 8.57842712,7.40685425 7.99264069,7.99264069 C7.40685425,8.57842712 6.45710678,8.57842712 5.87132034,7.99264069 L4.81066017,6.93198052 C4.22487373,6.34619408 4.22487373,5.39644661 4.81066017,4.81066017 Z M4.81066017,19.2426407 C4.22487373,18.6568542 4.22487373,17.7071068 4.81066017,17.1213203 L5.87132034,16.0606602 C6.45710678,15.4748737 7.40685425,15.4748737 7.99264069,16.0606602 C8.57842712,16.6464466 8.57842712,17.5961941 7.99264069,18.1819805 L6.93198052,19.2426407 C6.34619408,19.8284271 5.39644661,19.8284271 4.81066017,19.2426407 Z" fill="#fff" fill-rule="nonzero" opacity="0.3"/>
     
        </svg>
      </button>

    <!-- Theme switcher script -->
    <script>
        const toggleThemeButton = document.getElementById("toggle-theme-button");
        const lightIcon = document.getElementById("light-icon");
        const darkIcon = document.getElementById("dark-icon");
        function toggleTheme() {
            document.body.classList.toggle("dark-theme");
        }
    </script>
  </body>
</html>
